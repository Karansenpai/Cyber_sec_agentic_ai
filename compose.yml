version: '3.8'

services:
  # Zookeeper - Required for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - ./data/zookeeper/data:/var/lib/zookeeper/data
      - ./data/zookeeper/log:/var/lib/zookeeper/log
    networks:
      - cyber_net
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      interval: 10s
      retries: 20
      start_period: 10s
      timeout: 10s

  # Kafka - Message broker for data ingestion
  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka/data:/var/lib/kafka/data
    networks:
      - cyber_net
    healthcheck:
      test: kafka-topics --bootstrap-server kafka:29092 --list || exit 1
      interval: 10s
      retries: 20
      start_period: 10s
      timeout: 10s
      
  # Kafka UI - Web interface for Kafka management
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - cyber_net

  # Kafka topics initialization
  kafka-init:
    build:
      context: .
      dockerfile: ./docker/kafka-init.Dockerfile
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    networks:
      - cyber_net
    restart: on-failure

  # Elasticsearch - For log storage
  elasticsearch:
    image: elasticsearch:8.6.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    networks:
      - cyber_net
    healthcheck:
      test: curl -s http://localhost:9200 || exit 1
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Kibana - For visualization 
  kibana:
    image: kibana:8.6.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - cyber_net
    healthcheck:
      test: curl -s http://localhost:5601/api/status || exit 1
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 10s

  # Data producer service - Simulates data sources
  data-producer:
    build:
      context: .
      dockerfile: ./docker/data-producer.Dockerfile
    container_name: data-producer
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    networks:
      - cyber_net
    restart: unless-stopped

  # Data consumer service - Processes kafka events
  data-consumer:
    build:
      context: .
      dockerfile: ./docker/data-consumer.Dockerfile
    container_name: data-consumer
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    networks:
      - cyber_net
    restart: unless-stopped

  # Phase 2: Anomaly Detection Service - AI-based threat detection
  anomaly-detection:
    build:
      context: .
      dockerfile: ./docker/anomaly-detection.Dockerfile
    container_name: anomaly-detection
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      elasticsearch:
        condition: service_healthy
      data-consumer:
        condition: service_started
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./data/models:/app/data/models
    networks:
      - cyber_net
    restart: unless-stopped
    # Add GPU support if available (uncomment if using GPUs)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Phase 3: Orchestration Service - Autonomous Decision-Making & Response
  orchestrator:
    build:
      context: .
      dockerfile: ./docker/orchestrator.Dockerfile
    container_name: orchestrator
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      elasticsearch:
        condition: service_healthy
      anomaly-detection:
        condition: service_started
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}  # Required for LangChain
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./data/vector_db:/app/data/vector_db
    networks:
      - cyber_net
    restart: unless-stopped

  # Phase 4: Feedback Loop for Continuous Learning & Model Refinement
  feedback-loop:
    build:
      context: .
      dockerfile: ./docker/feedback-loop.Dockerfile
    container_name: feedback-loop
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      elasticsearch:
        condition: service_healthy
      orchestrator:
        condition: service_started
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}  # Required for VectorDB embeddings
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./data/vector_db:/app/data/vector_db
      - ./data/models:/app/data/models
    networks:
      - cyber_net
    restart: unless-stopped

  # Phase 4: Dashboard Service for Monitoring & Alerting
  dashboard-service:
    build:
      context: .
      dockerfile: ./docker/dashboard-service.Dockerfile
    container_name: dashboard-service
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy  # Changed to ensure Kibana is fully ready
      kafka:
        condition: service_healthy  # Added dependency on Kafka
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    networks:
      - cyber_net
    restart: unless-stopped

networks:
  cyber_net:
    driver: bridge